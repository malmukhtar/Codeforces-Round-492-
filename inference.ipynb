{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malmukhtar/Codeforces-Round-492-/blob/master/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "L7qXulgIEz1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a066d4f3-f002-437b-ffc5-2566cdf1ebff"
      },
      "cell_type": "code",
      "source": [
        "# if running locally, comment these lines\n",
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==1.10.1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.8/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.8/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.8/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.8/dist-packages)\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.10.1 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for tensorflow==1.10.1\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "CiQ4JfXOCOln",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "e7ac7a94-e952-4e5c-c3ac-847d682c73e7"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d1ab3a3b30cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'enable_eager_execution'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "tQP-RMW-_VWg"
      },
      "cell_type": "code",
      "source": [
        "# if running locally, comment these lines\n",
        "!wget https://www.dropbox.com/s/4tjix8rhyzxpc28/dataset.tar.gz\n",
        "!wget https://www.dropbox.com/s/zj1v8n5href2mtu/tboard_logs.tar.gz\n",
        "!tar -xvzf dataset.tar.gz\n",
        "!tar -xvzf tboard_logs.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HWvDSMxt_-n2"
      },
      "cell_type": "code",
      "source": [
        "# if running locally, comment these lines\n",
        "!mkdir src\n",
        "!wget https://raw.githubusercontent.com/sthalles/face-similarity/master/src/contrastive.py\n",
        "!wget https://raw.githubusercontent.com/sthalles/face-similarity/master/src/cyclical_lr.py\n",
        "!wget https://raw.githubusercontent.com/sthalles/face-similarity/master/src/pre_processing.py\n",
        "!wget https://raw.githubusercontent.com/sthalles/face-similarity/master/src/utils.py\n",
        "!mv contrastive.py ./src/\n",
        "!mv cyclical_lr.py ./src/\n",
        "!mv pre_processing.py ./src/\n",
        "!mv utils.py ./src/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H3ci1KMnDMn5"
      },
      "cell_type": "code",
      "source": [
        "# if running locally, comment these lines\n",
        "!mkdir model\n",
        "!wget https://raw.githubusercontent.com/sthalles/face-similarity/master/model/densenet.py\n",
        "!mv densenet.py ./model/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O7oM-tSY_BUq"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from model.densenet import DenseNet\n",
        "from src.pre_processing import *\n",
        "import matplotlib.pyplot as plt\n",
        "from src.contrastive import contrastive_loss\n",
        "import json\n",
        "from src.utils import Dotdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CnAUUFOp_BUw"
      },
      "cell_type": "code",
      "source": [
        "work_dir = './tboard_logs'\n",
        "model_id = 31911\n",
        "test_dataset_path = './dataset/test_v2.tfrecords'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IyP4LZWX_BUy"
      },
      "cell_type": "code",
      "source": [
        "checkpoint_dir = os.path.join(work_dir, str(model_id))\n",
        "\n",
        "# load training metadata (setup path if necessary)\n",
        "with open(checkpoint_dir + '/meta.json', 'r') as fp:\n",
        "    training_args = Dotdict(json.load(fp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mG39k2Mo_BU0"
      },
      "cell_type": "code",
      "source": [
        "tfe = tf.contrib.eager\n",
        "test_filenames = [test_dataset_path]\n",
        "test_dataset = tf.data.TFRecordDataset(test_filenames)\n",
        "test_dataset = test_dataset.map(tf_record_parser)\n",
        "test_dataset = test_dataset.map(random_resize_and_crop)\n",
        "test_dataset = test_dataset.map(normalizer)\n",
        "test_dataset = test_dataset.shuffle(1000)\n",
        "test_dataset = test_dataset.batch(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gC-RSW9Y_BU3"
      },
      "cell_type": "code",
      "source": [
        "args = {\"k\": training_args.growth_rate,\n",
        "        \"weight_decay\": training_args.l2_regularization,\n",
        "        \"num_outputs\": training_args.num_outputs,\n",
        "        \"units_per_block\": training_args.units_per_block,\n",
        "        \"momentum\": training_args.momentum,\n",
        "        \"epsilon\": training_args.epsilon,\n",
        "        \"initial_pool\": training_args.initial_pool}\n",
        "\n",
        "model = DenseNet(**args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uJAEAO4F_BU5"
      },
      "cell_type": "code",
      "source": [
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "root = tfe.Checkpoint(model=model,\n",
        "                      optimizer_step=tf.train.get_or_create_global_step())\n",
        "\n",
        "try:\n",
        "    root.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "    print(\"Model {} successfully loaded.\".format(model_id))\n",
        "except:\n",
        "    print(\"Error loading model: {}\".format(FLAGS.model_id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6EPImRWJ_BU7"
      },
      "cell_type": "code",
      "source": [
        "mean_similarity = []\n",
        "mean_dissimilarity = []\n",
        "\n",
        "for (batch, (Xi, Xj, label)) in enumerate(test_dataset):\n",
        "\n",
        "    with tf.contrib.summary.record_summaries_every_n_global_steps(100):\n",
        "\n",
        "        GX1 = model(Xi, training=False)\n",
        "        GX2 = model(Xj, training=False)\n",
        "        _, Dw = contrastive_loss(GX1, GX2, label, margin=2.)\n",
        "\n",
        "        f, axarr = plt.subplots(2, 8, figsize=(16,4))\n",
        "        f.subplots_adjust(hspace=0.3)\n",
        "\n",
        "        for i in range(label.shape[0]):\n",
        "\n",
        "            Si = denormalize(Xi[i]).numpy()\n",
        "            Sj = denormalize(Xj[i]).numpy()\n",
        "\n",
        "            if label[i].numpy() == 0:\n",
        "                mean_similarity.append(Dw[i])\n",
        "            else:\n",
        "                mean_dissimilarity.append(Dw[i])\n",
        "\n",
        "            axarr[0, i].set_title('Sim: ' + str(Dw[i].numpy()))\n",
        "            axarr[0,i].imshow(np.squeeze(Si))\n",
        "            axarr[0,i].set_axis_off()\n",
        "\n",
        "            axarr[1,i].set_title(\"Label: \" + str(label[i].numpy()))\n",
        "            axarr[1,i].imshow(np.squeeze(Sj))\n",
        "            axarr[1,i].set_axis_off()\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "mean_std_similarity_np = np.std(mean_similarity)\n",
        "mean_std_dissimilarity_np = np.std(mean_dissimilarity)\n",
        "mean_similarity_np = np.mean(mean_similarity)\n",
        "mean_dissimilarity_np = np.mean(mean_dissimilarity)\n",
        "\n",
        "print(\"Mean similarity {0} Mean Std: {1}.\".format(mean_similarity_np, mean_std_similarity_np))\n",
        "print(\"Mean dissimilarity {0} Mean Std: {1}.\".format(mean_dissimilarity_np, mean_std_dissimilarity_np))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JSZuVK6B_BU9"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}